---
title: Risks of artificial intelligence
description: AI threatens our democracy, our technology, and our species.
---

AI is a powerful technology that is increasingly transforming our world.
It comes with amazing potential, but also with serious risks, including [existential catastrophe](/xrisk).

## Fake media

Much of our society is based on trust. We trust that the money in our bank account is real, that the news we read is true, and that the people who post reviews online exist.

AI systems are exceptionally good at creating fake media. They can create fake videos, fake audio, fake text, and fake images.
These capabilities are improving rapidly.
Just two years ago, we laughed at the horribly unrealistic dall-e images, but now we have [deepfake images winning photography contests](https://www.theguardian.com/technology/2023/apr/17/photographer-admits-prize-winning-image-was-ai-generated).
GPT-4 can write in a way that is indistinguishable from humans.

Creating fake media is not new, but AI makes it much cheaper and much more realistic.
An AI-generated image of an explosion caused [panic sells in wall street](https://www.euronews.com/next/2023/05/23/fake-news-about-an-explosion-at-the-pentagon-spreads-on-verified-accounts-on-twitter).
We might soon see social media be flooded with fake discussions and opinions, and fake news articles that are indistinguishable from real ones.
This could erode the trust we have in our society.
It could threaten the fundamentals of our democracy even more than social media did.

## Biases and discrimination

AI systems are trained on data, and much of the data we have is in some way biased.
This means that AI systems will inherit the biases of our society.
An automated recruitment system at Amazon [inherited a bias against women](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G).
Black patients were [less likely to be referred to a medical specialist](https://www.science.org/doi/full/10.1126/science.aax2342).
These biases often appear without the creators of the AI system being aware of them.

## Economic inequality, instability and job loss

During the industrial revolution, many people lost their jobs to machines.
However, new (often better) jobs were created, and the economy grew.
This time, things might be different.

AI does not just replaces our muscles as the steam engine did, it replaces our brains.
Regular humans may not have anything left to offer the economy.
Image generation models (which are heavily trained on copyrighted material from professional artists) are already [impacting the creative industry](https://cointelegraph.com/news/artists-face-a-choice-with-ai-adapt-or-become-obsolete).
Writers are [striking](https://www.newscientist.com/article/2373382-why-use-of-ai-is-a-major-sticking-point-in-the-ongoing-writers-strike/).
GPT-4 has passed the bar exam, can write excellent written content, and can write code (again, trained on often copyrighted materials).
The people who own these AI systems will be able to capitalize on them, but the people who lose their jobs to them will not.
The way we distribute wealth in our society is not prepared for this.

## Computer viruses and hacks

Virtually everything we do nowadays is in some way dependent on computers.
We pay for our groceries, plan our days, contact our loved ones and even drive our cars with computers.

Modern AI systems can analyze and write software.
They [can find vulnerabilities](https://betterprogramming.pub/i-used-gpt-3-to-find-213-security-vulnerabilities-in-a-single-codebase-cc3870ba9411) in software, and [they could be used to exploit them](https://blog.checkpoint.com/2023/03/15/check-point-research-conducts-initial-security-analysis-of-chatgpt4-highlighting-potential-scenarios-for-accelerated-cybercrime/).
As AI capabilities grow, so will the capabilities of the exploits they can create.

Highly potent computer viruses have always been extremely hard to create, but AI could change that.
Instead of having to hire a team of highly skilled security experts/hackers to find zero-day exploits, you could just use a far cheaper AI to do it for you.

[Read more about AI and cybersecurity risks](/cybersecurity-risks)

## Existential Risk

Over half of AI researchers believe there is a >10% chance that AI will cause human extinction.
Would you enter a plane if half of the plane engineers believed there was a >10% chance that it would crash?

Very intelligent things are very powerful.
If we build a machine that is far more intelligent than humans, we need to be sure that it wants the same thing as we want.
However, this turns out to be very difficult.
This is called the _alignment problem_.
If we fail to solve it in time, we are likely to end up with an unstoppable machine making decisions for us that is not considering our well-being.

[Read more about x-risk](/xrisk)
