---
title: AI Safety Summit
description: What it would take to organize a summit on AI safety.
---

AI presents very real risks to humanity, including the [risk of extinction](/xrisk).
Progress in AI capabilities is accelerating at a [frantic pace](/urgency), and we are not prepared for the consequences.
AI companies are locked in a race to the bottom, where safety is not the highest priority.
We need governments to step in and regulate AI development.
This needs to happen on an international level.
**The only way to achieve this is through a summit.**
The primary goal of PauseAI is to convince one government to organize such a summit.

But what does such a summit look like?
Well, it will be a meeting of national governments, hosted by one of them.
A summit can take many days and will be attended by many people.
Organizing it is a monumental task, and we are not experts in this field.

The goal of the Summit itself is a _treaty_, which is a formal agreement between two or more states in reference to peace, alliance, commerce, or other international relations.
In our case, the AI Safety Treaty should be an agreement between the participating states to pause AI development until the risks are better understood.

## Organizing a summit

One government will have to take the lead in organizing the summit.
This government will be the host of the summit and will be responsible for the logistics.
They need to find a suitable date and location, arrange the catering, draft the agenda, and invite the other governments.

## Examples of Summits and resulting treaties

- **Montreal Protocol** (1987): The Montreal Protocol is an international environmental treaty designed to protect the ozone layer by phasing out the production and consumption of ozone-depleting substances. It has been highly successful in reducing the use of substances like chlorofluorocarbons (CFCs) and has contributed to the gradual recovery of the ozone layer.
- **Stockholm Convention on Persistent Organic Pollutants** (2001): The Stockholm Convention is an international treaty aimed at protecting human health and the environment from persistent organic pollutants (POPs). These are toxic chemicals that persist in the environment, bioaccumulate in living organisms, and can have serious adverse effects on human health and ecosystems. Scientists raised concerns about the harmful effects of POPs, including their ability to travel long distances through air and water currents. The convention led to the banning or severe restrictions on the production and use of several POPs, including polychlorinated biphenyls (PCBs), dichlorodiphenyltrichloroethane (DDT), and dioxins.

## Treaty

The treaty is the most important outcome of the summit.
It is the document that will be signed by the participating states and will be the basis for future negotiations.

We propose that the treaty should contain the following:

- Set up an international AI safety agency, similar to the IAEA.
- Ban on the development of AI systems more powerful than GPT-4, until the risks are better understood.
  - Require approval to conduct any new training run above a certain size (e.g. 1 billion parameters).
- Periodic meetings to discuss the progress of AI safety research.
- Agreements on increasing national investments in AI safety research.

You can take inspiration from:

- [stop.ai/proposals](https://www.stop.ai/proposals)

## Suggested agenda

Many people will be attending the summit, and not all of them will be deeply familiar with AI safety.
They must be able to follow the discussions and make informed decisions.

The following is a suggested agenda for the summit:

- Introduction to Artificial Intelligence
  - Neural networks
  - Large language models
  - Market dynamics of AI
- AI safety
  - What is Superintelligence
  - The alignment problem
  - Instrumental convergence
- AI safety policy
  - International level
  - Funding AI safety research
  - Risks of AI research publications
  - Governance of open source models
