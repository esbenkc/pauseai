---
title: PauseAI candlelit vigil @ UN HQ NYC, 3rd of June
---

- Candlelit vigil to raise awareness about the existential risk of AI.
- 3rd of June, 7:30PM to 9PM. Sun sets at 8:15 here.
- United Nations Headquarters in New York City.

## Press Release

On Saturday, June 3rd, at sunset, a candlelit vigil will take place in front of the United Nations. Volunteers from the new [PauseAI](http://pauseai.info) movement will gather there to urge governments to discuss the dangers of AI at a summit conference.

Half of AI researchers [believe](https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/) that there is a 10% or greater chance that the invention of superhuman AI will mean the end of humanity. Would you board an airplane if half of the aircraft engineers thought there was a 10% chance of it crashing?

Prominent examples of people warning about the dangers of AI include Prof. [Geoffrey Hinton](https://www.reuters.com/technology/ai-pioneer-says-its-threat-world-may-be-more-urgent-than-climate-change-2023-05-05/) and Prof. [Yoshua Bengio](https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/), both Turing Award winners and pioneers of the most successful AI methods today. Not only scientists but also leaders of AI companies themselves are concerned about this danger:

- Sam Altman (CEO of OpenAI, the company behind ChatGPT): ["Development of superhuman machine intelligence is probably the greatest threat to the continued existence of humanity."](https://blog.samaltman.com/machine-intelligence-part-1)
- Elon Musk (co-founder of OpenAI): ["AI has the potential of civilizational destruction."](https://www.inc.com/ben-sherry/elon-musk-ai-has-the-potential-of-civilizational-destruction.html)
- Bill Gates (co-founder of Microsoft, owning 50% of OpenAI): ["AI could decide that humans are a threat."](https://www.denisonforum.org/daily-article/bill-gates-ai-humans-threat/)
- Jaan Tallinn (lead investor at Anthropic, builders of Claude): ["I've not met anyone in AI labs who says the risk [from training a next-gen model] is less than 1% of blowing up the planet. It's important that people know lives are being risked."](https://twitter.com/liron/status/1656929936639430657)

The advancements in the AI landscape have exceeded expectations. In 2020, it was estimated that an AI system would pass university entrance exams by 2050. This goal was achieved in March 2023 by OpenAI's GPT-4. This AI has a [verbal IQ of 155](https://bgr.com/tech/chatgpt-took-an-iq-test-and-its-score-was-sky-high/), speaks 23 languages, can program, and [can deceive people](https://www.theinsaneapp.com/2023/03/gpt4-passed-captcha-test.html). Fortunately, GPT-4 still has limitations. For example, it cannot effectively [hack or write computer viruses](https://pauseai.info/cybersecurity-risks), but it's possible that these skills are only a few innovations away. Given the current pace of AI investment, this point is [rapidly approaching](https://pauseai.info/urgency).

These massive and unexpected leaps in capabilities have prompted many experts to request a pause in the development of AI through an [open letter](https://futureoflife.org/open-letter/pause-giant-ai-experiments/) addressed to major AI companies. The letter has been signed over 27,000 times, mostly by AI researchers and tech luminaries. A pause is needed to work on AI legislation, work on the AI alignment problem and adjust as a society to this new technology. A [recent survey](https://forum.effectivealtruism.org/posts/EoqeJCBiuJbMTKfPZ/unveiling-the-american-public-opinion-on-ai-moratorium-and) in the United States shows significant support for a pause with more than 60% of the public in favor. Unfortunately, it appears that companies are not willing to voluntarily jeopardize their competitive positions by stopping. These AI companies are locked in a race to the bottom, where safety increasingly takes a back seat to improving capabilities. Therefore, the pause must be imposed by governments. Implementing a national pause is also challenging as countries have reasons not to be the first to pause. Therefore, an international solution is needed: a summit. PauseAI is calling on our governments to organize that summit.

For more information, please visit [PauseAI.info](http://pauseai.info).
